[00:00:00]
>> One thing I do want to show you actually, I have a link here in the notes. There are a lot of stages. So I showed you a bucket I showed you he can do count. Match. I showed you match. I showed you sort there's projectors redact, replace with sample.

[00:00:22]
Also, like there's a lot of different stuff you can do with the aggregation. Pipeline. How do you query buckets once you've gone through the aggregation pipeline. What you get back is an array of objects and you can treat those as you would basically documents. Otherwise in your yourself.

[00:00:37]
Collection. Beyond that, I'd have to go look at exactly how you do it because I don't remember off the top my head every time that I do the aggregation pipeline stuff, I have to go and read the docs line by line because it's not something that I end up doing very frequently.

[00:00:53]
But it's not terribly difficult you just end up acquiring them like odd like normal objects. There's nothing special you need to treat them. In fact, you can see here I did literally query them right here. With the sword I just said, hey, sort this and count by negative one.

[00:01:09]
You could bucket these again by saying here's all the ones that have more than 800. And here's all the ones that have less than 800. It's all just objects to MongoDB. That's a good question. Are the buckets saved or indexed or anything like that? Not by default, by default, it's just gonna print out what you ask it to print out.

[00:01:29]
It does have the ability to actually write to another collection. So let's say you're doing like daily stats on how many people visited your website, right and you were keeping all of your sessions in a database. One that's not really a good use case for MongoDB. But you could potentially hit the software exists to do that.

[00:01:48]
And then at the end of the day, you wanted to aggregate that into like, how many Firefox users visited and how many. Chrome users and edge users and all that kind of stuff. You could do that with the aggregation pipeline. And then you could have that right to another, like daily starts collection and then you could read from that collection.

[00:02:07]
Every day, right? So by default, it doesn't save anywhere. But you could write that to a another collection. Obviously, that's not gonna be indexed by default either, but there's no reason you couldn't index that as well. Michael see, so is there any documentation we can go explore I left some link to it in the course notes.

[00:02:30]
It's on the aggregation page at the bottom. I'm sure. Front of masters will also put a course note here. Actually. I don't know,
>> Put it on the object. IDs are randomly generated. Are. Is there any serial order father?
>> That's a good question are the like let's see if I can find one in here.

[00:02:51]
Yeah, like these object IDs right here. I don't actually really know precisely the algorithm that goes into the one thing that I do know is it actually does create does contain a time stamp in it. So it is based on the time when was written, you can actually pull the time stamp out of it.

[00:03:08]
You'd have to go look it up if you just search for like MongoID. Time stamp, it'll contain the creation time in it. So you can actually, you don't actually if you're looking at creation times, just know that the object idea automatically contains that whether or not you created or not.

[00:03:27]
That's the only interesting thing I can remember about it. And the other thing is it's always guaranteed unique. But the randomization is through the time. Even if two objects are inserted relatively close to each other in time. They will never have the same ID this this object ID here 100% of the time will always be totally unique to that object.

[00:03:49]
Good question.

